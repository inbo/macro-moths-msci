---
title: "Calculate multi-species trends by traits"
author: "Ward Langeraert"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
bibliography: [references.json]
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/research-institute-for-nature-and-forest.csl
---

```{r setup, include=FALSE}
# Set up
library(knitr)
library(here)
opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)
opts_knit$set(root.dir = here::here())

conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::select)

# Packages
library(tidyverse)
library(brms)
library(posterior)
```

# Goal

Calculate model based species change indices for certain traits.

# Load data

```{r}
out_path <- file.path("data", "processed")

species_traits_final_nozero <- read_csv(
  file.path(out_path, "prop_data_per_trait_nozero.csv")
)
species_traits_final <- read_csv(file.path(out_path, "prop_data_per_trait.csv"))
```

# Model specification

We assume a multinomial distribution per period $j$ ($j = 1, 2$) for the number of grid squares $n$ per species $i$ ($i = 1, ..., S$).

$$
\{n_{1j}, ...n_{2j}\} \sim Multinom(\sum_{i=1}^S n_{ij}, \{p_{1j}, ...p_{2j}\})
$$

Where $p_{ij} = \frac{\lambda_{ij}}{\lambda_{1j} + ... + \lambda_{Sj}}$

$\{n_{1j}, ...n_{2j}\}$ can be interpreted as independent Poisson random variables

$$
n_{ij} \sim Poisson(\lambda_{ij})
$$

Such that we can specify the model

$$
\ln(\lambda_{ij}) = \beta_0 + \beta_{msci}X_{period} + ln(\Sigma_{i=1}^Sn_{ij}) + b_{0,{i = 1, ..., S}} + b_{1,{i = 1, ..., S}}X_{period}
$$

Where

-   $\beta_0$ the average log-number of grids for period 1
-   $\beta_{msci}$ the effect of period 2 compared to period 1 such that $MSCI = \exp(\beta_{msci})$
-   $X_{period}$ is 0 if period is 1980-2012 and 1 if period is 2013-2022
-   $ln(\Sigma_{i=1}^Sn_{ij})$ an offset used to control for the disproportionate search effort between the two periods
-   $b_{0,{i = 1, ..., S}}$ a random intercept for each species: deviation per species from $\beta_0$
-   $b_{1,{i = 1, ..., S}}$ a random slope for each species: deviation per species from $\beta_{msci}$

We set $corr(b_0, b_1) = 0$ since we want a separate (uncorrelated) deviation for both periods.

Example for trait 'Activity'. First for trait value 'DayActive'.

```{r}
# instruct brms to use cmdstanr as backend and cache all Stan binaries
options(brms.backend = "cmdstanr", 
        cmdstanr_write_stan_file_dir = here("brms_cache"))
# create cache directory if not yet available
dir.create(here("brms_cache"), FALSE)

## some nifty utility functions:

## converts a matrix of draws as returned by brms into a vector of an rvar
to_rvar_vector <- function(draw_matrix) {
    lab <- "rv"
    mdraws <- as_draws_matrix(draw_matrix)
    variables(mdraws) <- paste0(lab, "[", 1:nvariables(mdraws), "]")
    as_draws_rvars(mdraws)[["rv"]]
}

## simplifying functions to work with models in the context of data.frames
rv_posterior_epred <- function(newdata, model, ...) {
    to_rvar_vector(posterior_epred(model, newdata = newdata, ...))
}
```

```{r}
dat <- species_traits_final %>%
  filter(trait_value == "DayActive")

# MCMC parameters
nchains <- 3 # number of chains
niter <- 4000 # number of iterations (incl. burn-in)
burnin <- niter / 4 # number of initial samples to discard (burn-in)
nparallel <- nchains # number of cores used for parallel computing

fit <- brm(
  bf(n_grids ~ period + offset(log(sum_per_period)) +
    (1 + period || species_nl)),
  data = dat, family = poisson(),
  chains = nchains, warmup = burnin, iter = niter, cores = nparallel
)
```

Convergence ok. 

```{r}
plot(fit)
```

Model fit ok.

```{r}
pp_check(fit,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "period"
)
```

MSCI estimate:

```{r}
hypothesis(
  x = fit,
  "exp(periodp2013_2022) - 1 = 0",
  class = "b", alpha = 0.05
)
```

```{r}
post_dat <- dat %>%
  mutate(pm_count = rv_posterior_epred(., fit))

post_dat %>%
  mutate(pm_prop = pm_count / sum_per_period) %>%
  group_by(species_nl) %>%
  arrange(species_nl, trait_value, period) %>%
  mutate(sci = pm_prop / first(pm_prop)) %>%
  ungroup() %>%
  mutate(ln_sci = log(sci)) %>%
  group_by(period, trait_value) %>%
  summarise(msci = exp(rvar_mean(ln_sci)) - 1) %>%
  mutate(summarise_draws(msci, "mean", "median", "sd", ~quantile(.x, probs = c(0.025, 0.975))))
  
post_dat %>%
  mutate(pm_prop = pm_count / sum_per_period) %>%
  mutate(ln_sc = log(pm_prop)) %>%
  group_by(period, trait_value) %>%
  summarise(mean_count = exp(rvar_mean(ln_sc))) %>%
  ungroup() %>%
  arrange(trait_value, period) %>%
  mutate(msci = (mean_count / first(mean_count)) - 1) %>%
  mutate(summarise_draws(msci, "mean", "median", "sd", ~quantile(.x, probs = c(0.025, 0.975))))


test <- post_dat %>%
  mutate(si = pm_count / sum_per_period) %>%
  mutate(ln_si = log(si)) %>%
  group_by(period, trait_value) %>%
  summarise(msi = rvar_mean(ln_si)) %>%
  group_by(trait_value) %>%
  arrange(trait_value, period) %>%
  mutate(beta_p2013_2022 = msi - first(msi)) %>%
  ungroup() %>%
  mutate(msci = exp(beta_p2013_2022) - 1) %>%
  mutate(summarise_draws(msci, "mean", "median", "sd", ~quantile(.x, probs = c(0.025, 0.975))))
```

We also create a single model for all trait values in 'Activity'.

```{r}
dat2 <- species_traits_final %>%
  filter(trait_name == "Activity")

# MCMC parameters
nchains <- 3 # number of chains
niter <- 10000 # number of iterations (incl. burn-in)
burnin <- niter / 4 # number of initial samples to discard (burn-in)
nparallel <- nchains # number of cores used for parallel computing
thinning <- 2

fit2 <- brm(
  bf(n_grids ~ period * trait_value + offset(log(sum_per_period)) +
    (1 + period || species_nl)),
  data = dat2, family = poisson(),
  chains = nchains, warmup = burnin, iter = niter, cores = nparallel,
  thin = thinning
)
```

Convergence ok.

```{r}
plot(fit2)
```

Model fit ok.

```{r}
pp_check(fit2,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "period"
)
pp_check(fit2,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "trait_value"
)
```

Estimate MSCI 'DayActive':

```{r}
hypothesis(
  x = fit2,
  "exp(periodp2013_2022) - 1 = 0",
  class = "b", alpha = 0.05
)
```

Estimate MSCI 'DayNightActive':

```{r}
hypothesis(
  x = fit2,
  "exp(periodp2013_2022 + periodp2013_2022:trait_valueDayNightActive) - 1 = 0",
  class = "b", alpha = 0.05
)
```

Estimate MSCI 'NightActive':

```{r}
hypothesis(
  x = fit2,
  "exp(periodp2013_2022 + periodp2013_2022:trait_valueNightActive) - 1 = 0",
  class = "b", alpha = 0.05
)
```

```{r}
post_dat2 <- dat2 %>%
  mutate(pm_count = rv_posterior_epred(., fit2))

post_msci2 <- post_dat2 %>% 
  group_by(period, sum_per_period, trait_value) %>%
  summarise(mean_count = rvar_mean(pm_count)) %>%
  ungroup() %>%
  mutate(mean_prop = log(mean_count / sum_per_period)) %>%
  group_by(trait_value) %>%
  arrange(trait_value, period) %>%
  mutate(msci = mean_prop - first(mean_prop)) %>%
  ungroup()
```

test

```{r}
dat3 <- species_traits_final %>%
  filter(trait_name %in% c("EllenbergN", "Phagy")) %>%
  pivot_wider(id_cols = c(species_nl, n_grids, period, sum_per_period),
              names_from = trait_name, values_from = trait_value)

# MCMC parameters
nchains <- 3 # number of chains
niter <- 10000 # number of iterations (incl. burn-in)
burnin <- niter / 4 # number of initial samples to discard (burn-in)
nparallel <- nchains # number of cores used for parallel computing
thinning <- 2

fit3 <- brm(
  bf(n_grids ~ period * Phagy * EllenbergN + offset(log(sum_per_period)) +
    (1 + period || species_nl)),
  data = dat3, family = poisson(),
  chains = nchains, warmup = burnin, iter = niter, cores = nparallel,
  thin = thinning
)
```

```{r}
plot(fit3)
```

```{r}
pp_check(fit3,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "period"
)

pp_check(fit3,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "Phagy"
)

pp_check(fit3,
  type = "dens_overlay_grouped", ndraws = 100,
  group = "EllenbergN"
)
```


```{r}
post_dat3 <- dat3 %>%
  mutate(pm_count = rv_posterior_epred(., fit3))

post_msci <- post_dat3 %>% 
  group_by(period, Phagy, EllenbergN) %>%
  summarise(mean_count = rvar_mean(pm_count)) %>%
  ungroup()
```

